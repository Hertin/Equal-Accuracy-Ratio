{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "from easydict import EasyDict as edict\n",
    "from os.path import join\n",
    "from tqdm.auto import tqdm\n",
    "# sys.path.insert(0, '../..')\n",
    "if 'cd' not in globals():\n",
    "    cd = True\n",
    "    os.chdir('../..')\n",
    "from utils import extract_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/base_ctc_dialect.yml'\n",
    "config = edict(yaml.load(open(config_path), Loader=yaml.SafeLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_gpu': True,\n",
       " 'model': {'name': 'RNNCTC',\n",
       "  'encoder': {'name': 'GRUBNEncoder',\n",
       "   'bidirectional': True,\n",
       "   'dropout': 0.5,\n",
       "   'hidden_size': 64,\n",
       "   'num_layers': 4},\n",
       "  'decoder': {'name': 'CTCDecoder',\n",
       "   'dropout': 0.0,\n",
       "   'hidden_size': 128,\n",
       "   'num_layers': 4},\n",
       "  'checkpoint': None,\n",
       "  'save_dir': 'checkpoints/base'},\n",
       " 'train': {'dataset': 'DialectTranscriptionDataset',\n",
       "  'data_dir': 'data/dialect_transcription',\n",
       "  'meta_data': 'config/dialect_transcription/data/trans_train.csv',\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'lr_step': 5,\n",
       "  'num_workers': 8,\n",
       "  'grad_clip': 5.0,\n",
       "  'optimizer': 'adam',\n",
       "  'weight_decay': 0.0,\n",
       "  'mom': 0.9,\n",
       "  'end_epoch': 300,\n",
       "  'print_freq': 20},\n",
       " 'dev': {'dataset': 'DialectTranscriptionDataset',\n",
       "  'data_dir': 'data/dialect_transcription',\n",
       "  'meta_data': 'config/dialect_transcription/data/trans_dev.csv',\n",
       "  'print_freq': 500},\n",
       " 'test': {'dataset': 'DialectTranscriptionDataset',\n",
       "  'data_dir': 'data/dialect_transcription',\n",
       "  'meta_data': 'config/dialect_transcription/data/trans_test.csv',\n",
       "  'beam_size': 10,\n",
       "  'print_freq': 500},\n",
       " 'feature': {'save_dir': 'data/dialect_transcription/mfcc_40',\n",
       "  'input_dim': 40,\n",
       "  'window_size': 25,\n",
       "  'stride': 5,\n",
       "  'cmvn': True,\n",
       "  'type': 'melspectrogram'},\n",
       " 'data': {'sample_size': 20000,\n",
       "  'min_duration': 1,\n",
       "  'PAD_token': 0,\n",
       "  'SOS_token': 1,\n",
       "  'EOS_token': 2,\n",
       "  'vocab_size': 29}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "window_size = 0.02\n",
    "window_stride = 0.01\n",
    "window = 'hamming'\n",
    "def load_audio(path):\n",
    "    if type(path) is str:\n",
    "        sound, sample_rate = librosa.load(path, sr=16000)\n",
    "    elif type(path) is tuple and len(path) == 3:\n",
    "        path, start, duration = path\n",
    "        sound, sample_rate = librosa.load(path, sr=16000, offset=start, duration=duration)\n",
    "    # sample_rate, sound = read(path)\n",
    "    # sound = sound.astype('float32') / 32767  # normalize audio\n",
    "    if len(sound.shape) > 1:\n",
    "        if sound.shape[1] == 1:\n",
    "            sound = sound.squeeze()\n",
    "        else:\n",
    "            sound = sound.mean(axis=1)  # multiple channels, average\n",
    "    return sound\n",
    "\n",
    "def parse_audio(audio_path):\n",
    "\n",
    "    y = load_audio(audio_path)\n",
    "\n",
    "    n_fft = int(sample_rate * window_size)\n",
    "    win_length = n_fft\n",
    "    hop_length = int(sample_rate * window_stride)\n",
    "    # STFT\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length,\n",
    "                     win_length=win_length, window=window)\n",
    "    spect, phase = librosa.magphase(D)\n",
    "    # S = log(S+1)\n",
    "    spect = np.log1p(spect)\n",
    "    spect = torch.FloatTensor(spect)\n",
    "#     if self.normalize:\n",
    "    mean = spect.mean()\n",
    "    std = spect.std()\n",
    "    spect.add_(-mean)\n",
    "    spect.div_(std)\n",
    "\n",
    "#     if self.spec_augment:\n",
    "#         spect = spec_augment(spect)\n",
    "\n",
    "    return spect.numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'data/dialect_transcription/stft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f176363edb54035a5cdbf3bf5ec32fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47978), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th sample\n",
      "5000th sample\n",
      "10000th sample\n",
      "15000th sample\n",
      "20000th sample\n",
      "25000th sample\n",
      "30000th sample\n",
      "35000th sample\n",
      "40000th sample\n",
      "45000th sample\n",
      "mode dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883dda74fb9b4bee86b405592ac2ff55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6528), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th sample\n",
      "5000th sample\n",
      "mode test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480ad3dae4c84dd49b1cec0df2302f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6676), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th sample\n",
      "5000th sample\n"
     ]
    }
   ],
   "source": [
    "names = set()\n",
    "os.makedirs(config.feature.save_dir, exist_ok=True)\n",
    "for mode in ['train', 'dev', 'test']:\n",
    "    print('mode', mode)\n",
    "    df = pd.read_csv(config[mode].meta_data)\n",
    "    for i, sample in tqdm(df.iterrows(), total=len(df)):\n",
    "        if i % 5000 == 0:\n",
    "            print(f'{i}th sample')\n",
    "        wave = sample['file']\n",
    "        speaker = sample['speaker']\n",
    "        start_time, duration_time = sample.start, sample.duration\n",
    "        input_file = join(config[mode].data_dir, wave)\n",
    "        feature = parse_audio((input_file, start_time, duration_time))\n",
    "        save_name = f\"{wave.replace('/','-')}-{'{:.2f}'.format(start_time)}-{'{:.2f}'.format(duration_time)}\"\n",
    "        save_path = join(save_dir, save_name)\n",
    "        assert save_name not in names\n",
    "        names.add(save_name)\n",
    "        np.save(save_path, feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "int(math.floor((sample_rate * window_size) / 2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
